# Скрипт для обхода сайта с crawl4ai

Обходит сайт и сохраняет контент страниц в .md файлы для дальнейшего использования в AI.

**Особенности:**
- Обход только в пределах указанного домена (BFS)
- Древовидная структура файлов, отражающая URL
- Логирование и статистика
- Автоматическое фильтрование нерелевантного контента

## Установка

```bash
pip install -r requirements.txt
crawl4ai-setup
playwright install chromium
```

## Использование

```bash
python crawler.py -u <URL> [-s <SITE_CODE>] [-m <MAX_PAGES>] [-o <OUTPUT_DIR>]
```

### Аргументы

- `-u, --base-url` — стартовый URL сайта (обязательно)
- `-s, --site-code` — необязательный ярлык для имени папки/лога и префикса файлов; если не указано, берется домен сайта
- `-m, --max-pages` — максимум страниц (по умолчанию: 50)
- `-o, --output-dir` — директория для сохранения (по умолчанию: `./output`)

**Примечание:** `site-code` — это просто название, которое вы придумываете сами. Если параметр не передан, в качестве имени папки/лога и префикса файлов используется домен сайта.

### Примеры

```bash
# Тестовый запуск без собственного имени (имя берется из домена)
python crawler.py -u https://example.com -m 10

# Полный обход с именем "example"
python crawler.py -u https://example.com -s example -m 100 -o ./results

# Реальный пример (имя можно выбрать любое или не указывать)
python crawler.py -u https://mysite.com -s mysite -m 50
```

## Формат выходных файлов

Все файлы сохраняются в одну папку с уникальными именами. Папка внутри `output` берется из домена сайта:

```
output/
  <domain_или_site-code>/
    <name>_index_<hash>.md
    <name>_about_<hash>.md
    <name>_article_<hash>.md
```

Каждый файл начинается с метаданных (URL и заголовок):

```markdown
---
URL: https://example.com/about
Заголовок: О нас
---

[Содержимое страницы в markdown...]
```

Имена файлов формируются на основе:
- Префикс `site-code` или домен
- Последняя часть пути URL
- Хеш URL для уникальности

## Логирование

Логи сохраняются в `output/logs/<имя>.log` (уровень DEBUG), где `<имя>` — переданный `site-code` или домен. В консоль выводится информация уровня INFO.

## Статистика

По завершении обхода выводится статистика:
- Количество обработанных страниц (успешно/ошибки)
- Количество сохраненных файлов
- Найдено/добавлено ссылок
- Время работы
- Типы ошибок
